# core/data_fetcher.py
import time

import pandas as pd
from typing import Optional, List, Dict, Any
from datetime import datetime, timedelta
from functools import lru_cache
import asyncio
from collections import defaultdict
from core.adaptive_cache import get_cache_manager
from core.bybit_connector import BybitConnector
from utils.logging_config import get_logger
from config import trading_params
from core.enums import Timeframe

logger = get_logger(__name__)


class CachedData:
  """–ö–ª–∞—Å—Å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å –≤—Ä–µ–º–µ–Ω–µ–º –∂–∏–∑–Ω–∏"""

  def __init__(self, data: Any, ttl: int = 300):
    self.data = data
    self.timestamp = datetime.now()
    self.ttl = ttl  # Time to live –≤ —Å–µ–∫—É–Ω–¥–∞—Ö

  def is_valid(self) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã –ª–∏ –µ—â–µ –¥–∞–Ω–Ω—ã–µ"""
    return (datetime.now() - self.timestamp).seconds < self.ttl


class DataFetcher:
  def __init__(self, connector: BybitConnector, settings: Dict[str, Any]):
    self.connector = connector
    self.settings = settings

    # –ö—ç—à–∏ –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤ –¥–∞–Ω–Ω—ã—Ö
    self.instrument_info_cache: Dict[str, CachedData] = {}
    self.symbols_cache: Optional[CachedData] = None
    self.candles_cache: Dict[str, CachedData] = {}

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
    self.instrument_cache_ttl = 3600  # 1 —á–∞—Å –¥–ª—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞—Ö
    self.symbols_cache_ttl = 600  # 10 –º–∏–Ω—É—Ç –¥–ª—è —Å–ø–∏—Å–∫–∞ —Å–∏–º–≤–æ–ª–æ–≤
    self.candles_cache_ttl = 60  # 1 –º–∏–Ω—É—Ç–∞ –¥–ª—è —Å–≤–µ—á–µ–π

    # –ë–ª–æ–∫–∏—Ä–æ–≤–∫–∏ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
    self.fetch_locks = defaultdict(asyncio.Lock)

    # –°—á–µ—Ç—á–∏–∫–∏ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∫—ç—à–∞
    self.cache_hits = 0
    self.cache_misses = 0
    self.total_requests = 0

  def get_cache_stats(self) -> Dict[str, Any]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫—ç—à–∞"""
    hit_rate = self.cache_hits / self.total_requests if self.total_requests > 0 else 0
    return {
      'cache_hits': self.cache_hits,
      'cache_misses': self.cache_misses,
      'total_requests': self.total_requests,
      'hit_rate': hit_rate,
      'cached_instruments': len(self.instrument_info_cache),
      'cached_candles': len(self.candles_cache)
    }

  def clear_cache(self, cache_type: Optional[str] = None):
    """–û—á–∏—â–∞–µ—Ç –∫—ç—à"""
    if cache_type == 'instruments':
      self.instrument_info_cache.clear()
    elif cache_type == 'symbols':
      self.symbols_cache = None
    elif cache_type == 'candles':
      self.candles_cache.clear()
    else:
      # –û—á–∏—â–∞–µ–º –≤—Å–µ –∫—ç—à–∏
      self.instrument_info_cache.clear()
      self.symbols_cache = None
      self.candles_cache.clear()
    logger.info(f"–ö—ç—à –æ—á–∏—â–µ–Ω: {cache_type or '–≤—Å–µ'}")

  def _clean_expired_cache(self):
    """–£–¥–∞–ª—è–µ—Ç —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ –∑–∞–ø–∏—Å–∏ –∏–∑ –∫—ç—à–µ–π"""
    # –û—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
    expired_instruments = [
      symbol for symbol, cached in self.instrument_info_cache.items()
      if not cached.is_valid()
    ]
    for symbol in expired_instruments:
      del self.instrument_info_cache[symbol]

    # –û—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞ —Å–≤–µ—á–µ–π
    expired_candles = [
      key for key, cached in self.candles_cache.items()
      if not cached.is_valid()
    ]
    for key in expired_candles:
      del self.candles_cache[key]

    if expired_instruments or expired_candles:
      logger.debug(f"–û—á–∏—â–µ–Ω–æ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –∑–∞–ø–∏—Å–µ–π: –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã={len(expired_instruments)}, —Å–≤–µ—á–∏={len(expired_candles)}")

  async def get_instrument_info(self, symbol: str) -> Optional[Dict[str, Any]]:
    """–ü–æ–ª—É—á–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–µ —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
    self.total_requests += 1

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
    if symbol in self.instrument_info_cache:
      cached = self.instrument_info_cache[symbol]
      if cached.is_valid():
        self.cache_hits += 1
        logger.debug(f"–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–µ {symbol} –ø–æ–ª—É—á–µ–Ω–∞ –∏–∑ –∫—ç—à–∞")
        return cached.data

    self.cache_misses += 1

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–ª–æ–∫–∏—Ä–æ–≤–∫—É –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
    async with self.fetch_locks[f"instrument_{symbol}"]:
      # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—â–µ —Ä–∞–∑ –ø–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
      if symbol in self.instrument_info_cache and self.instrument_info_cache[symbol].is_valid():
        return self.instrument_info_cache[symbol].data

      logger.debug(f"–ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–µ {symbol} —Å –±–∏—Ä–∂–∏")

      try:
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∑–∞ –æ–¥–∏–Ω –∑–∞–ø—Ä–æ—Å –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        if not self.instrument_info_cache:  # –ï—Å–ª–∏ –∫—ç—à –ø—É—Å—Ç–æ–π, –∑–∞–≥—Ä—É–∂–∞–µ–º –≤—Å–µ
          instruments = await self.connector.get_instruments_info()

          # –ö—ç—à–∏—Ä—É–µ–º –≤—Å–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
          for inst in instruments:
            if inst.get('symbol'):
              self.instrument_info_cache[inst['symbol']] = CachedData(
                inst, self.instrument_cache_ttl
              )

          # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω—É–∂–Ω—ã–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç
          if symbol in self.instrument_info_cache:
            return self.instrument_info_cache[symbol].data
        else:
          # –ï—Å–ª–∏ –∫—ç—à –Ω–µ –ø—É—Å—Ç–æ–π, –Ω–æ –Ω—É–∂–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞ –Ω–µ—Ç, –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω–æ
          instruments = await self.connector.get_instruments_info()
          for inst in instruments:
            if inst.get('symbol') == symbol:
              self.instrument_info_cache[symbol] = CachedData(
                inst, self.instrument_cache_ttl
              )
              return inst

        logger.warning(f"–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–µ {symbol} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        return None

      except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ–± –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–µ {symbol}: {e}")
        return None

  async def get_active_symbols_by_volume(self, limit: int) -> List[str]:
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
    self.total_requests += 1

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
    if self.symbols_cache and self.symbols_cache.is_valid():
      self.cache_hits += 1
      cached_symbols = self.symbols_cache.data
      # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω—É–∂–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏–∑ –∫—ç—à–∞
      return cached_symbols[:limit]

    self.cache_misses += 1

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–ª–æ–∫–∏—Ä–æ–≤–∫—É –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –¥—É–±–ª–∏—Ä—É—é—â–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤
    async with self.fetch_locks["symbols"]:
      # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—â–µ —Ä–∞–∑ –ø–æ—Å–ª–µ –ø–æ–ª—É—á–µ–Ω–∏—è –±–ª–æ–∫–∏—Ä–æ–≤–∫–∏
      if self.symbols_cache and self.symbols_cache.is_valid():
        return self.symbols_cache.data[:limit]

      try:
        logger.info("–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤...")

        contracts = await self.connector.get_usdt_perpetual_contracts()
        if not contracts:
          logger.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –∫–æ–Ω—Ç—Ä–∞–∫—Ç–æ–≤ –æ—Ç Bybit.")
          return []

        high_volume_symbols = []
        min_volume_usdt = self.settings.get('min_24h_volume_usdt', 1000000)

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–æ–Ω—Ç—Ä–∞–∫—Ç—ã –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
        tasks = []
        for contract in contracts:
          symbol = contract.get('symbol')
          if symbol and "USDT" in symbol and "USDC" not in symbol:
            volume_24h_usdt = float(contract.get('turnover24h', 0))
            if volume_24h_usdt >= min_volume_usdt:
              high_volume_symbols.append({
                'symbol': symbol,
                'volume24h_usdt': volume_24h_usdt
              })

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –æ–±—ä–µ–º—É
        high_volume_symbols.sort(key=lambda x: x['volume24h_usdt'], reverse=True)

        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(high_volume_symbols)} —Å–∏–º–≤–æ–ª–æ–≤ —Å –æ–±—ä–µ–º–æ–º > {min_volume_usdt} USDT.")

        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –Ω–∞–ª–∏—á–∏—é –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        final_symbols = []

        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –¥–∞–Ω–Ω—ã—Ö
        check_tasks = []
        for item in high_volume_symbols[:limit * 2]:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–æ–ª—å—à–µ, —á–µ–º –Ω—É–∂–Ω–æ
          symbol = item['symbol']
          check_tasks.append(self._check_symbol_data_availability(symbol))

        # –ñ–¥–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –≤—Å–µ—Ö –ø—Ä–æ–≤–µ—Ä–æ–∫
        results = await asyncio.gather(*check_tasks, return_exceptions=True)

        for i, has_data in enumerate(results):
          if has_data and not isinstance(has_data, Exception):
            final_symbols.append(high_volume_symbols[i]['symbol'])
            if len(final_symbols) >= limit:
              break

        # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        self.symbols_cache = CachedData(final_symbols, self.symbols_cache_ttl)

        return final_symbols[:limit]

      except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤: {e}")
        return []

  async def get_symbols_by_volatility(self, symbols: List[str], limit: int = 20) -> List[Dict[str, Any]]:
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–∏–º–≤–æ–ª—ã, –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –ø–æ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ –∏ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏"""
    try:
      volatility_data = []

      # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ –≤—Å–µ—Ö —Ç–∏–∫–µ—Ä–∞—Ö –æ–¥–Ω–∏–º –∑–∞–ø—Ä–æ—Å–æ–º
      endpoint = "/v5/market/tickers"
      params = {'category': 'linear'}

      tickers_result = await self.connector._make_request('GET', endpoint, params, use_cache=True)

      if not tickers_result or not tickers_result.get('list'):
        logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —Ç–∏–∫–µ—Ä–æ–≤")
        return []

      all_tickers = tickers_result.get('list', [])

      # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
      ticker_dict = {ticker['symbol']: ticker for ticker in all_tickers}

      # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –∏–Ω—Ç–µ—Ä–µ—Å—É—é—â–∏–µ –Ω–∞—Å —Å–∏–º–≤–æ–ª—ã
      for symbol in symbols:
        if symbol not in ticker_dict:
          continue

        ticker = ticker_dict[symbol]

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
        price_change_24h = float(ticker.get('price24hPcnt', 0)) * 100  # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ –ø—Ä–æ—Ü–µ–Ω—Ç—ã
        volume_24h = float(ticker.get('turnover24h', 0))  # –û–±—ä–µ–º –≤ USD

        # –ü–æ–ª—É—á–∞–µ–º —Å–≤–µ—á–∏ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ ATR
        candles = await self.get_historical_candles(symbol, Timeframe.ONE_HOUR, limit=24)
        if not candles.empty and len(candles) >= 14:
          import pandas_ta as ta
          atr = ta.atr(candles['high'], candles['low'], candles['close'], length=14)
          if atr is not None and not atr.empty:
            current_atr = atr.iloc[-1]
            atr_percent = (current_atr / candles['close'].iloc[-1]) * 100
          else:
            atr_percent = abs(price_change_24h) / 10  # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
        else:
          atr_percent = abs(price_change_24h) / 10

        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
        volatility_score = abs(price_change_24h) * 0.5 + atr_percent * 0.5

        volatility_data.append({
          'symbol': symbol,
          'price_change_24h': price_change_24h,
          'volume_24h': volume_24h,
          'atr_percent': atr_percent,
          'volatility_score': volatility_score
        })

      # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
      volatility_data.sort(key=lambda x: x['volatility_score'], reverse=True)

      logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(volatility_data)} —Å–∏–º–≤–æ–ª–æ–≤ —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏")

      return volatility_data[:limit]

    except Exception as e:
      logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –æ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏: {e}")
      return []

  async def get_symbols_volatility_batch(self, symbols: List[str], limit: int = 20) -> List[Dict[str, Any]]:
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –ø–æ–ª—É—á–µ–Ω–∏—è –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏ —Å –±–∞—Ç—á–µ–≤–æ–π –∑–∞–≥—Ä—É–∑–∫–æ–π"""
    try:
      volatility_data = []

      # 1. –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Ç–∏–∫–µ—Ä—ã –æ–¥–Ω–∏–º –∑–∞–ø—Ä–æ—Å–æ–º
      endpoint = "/v5/market/tickers"
      params = {'category': 'linear'}

      tickers_result = await self.connector._make_request('GET', endpoint, params, use_cache=True)

      if not tickers_result or not tickers_result.get('list'):
        logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ —Ç–∏–∫–µ—Ä–æ–≤")
        return []

      all_tickers = tickers_result.get('list', [])
      ticker_dict = {ticker['symbol']: ticker for ticker in all_tickers}

      # 2. –§–∏–ª—å—Ç—Ä—É–µ–º —Å–∏–º–≤–æ–ª—ã –ø–æ –±–∞–∑–æ–≤—ã–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º
      candidates = []

      for symbol in symbols:
        if symbol not in ticker_dict:
          continue

        ticker = ticker_dict[symbol]
        price_change_24h = float(ticker.get('price24hPcnt', 0)) * 100
        volume_24h = float(ticker.get('turnover24h', 0))

        # –ë–∞–∑–æ–≤—ã–π —Ñ–∏–ª—å—Ç—Ä –ø–æ –∏–∑–º–µ–Ω–µ–Ω–∏—é —Ü–µ–Ω—ã
        if abs(price_change_24h) < 1.0:  # –ú–µ–Ω–µ–µ 1% - –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
          continue

        candidates.append({
          'symbol': symbol,
          'price_change_24h': price_change_24h,
          'volume_24h': volume_24h,
          'ticker': ticker
        })

      # 3. –°–æ—Ä—Ç–∏—Ä—É–µ–º –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –ø–æ –∏–∑–º–µ–Ω–µ–Ω–∏—é —Ü–µ–Ω—ã –∏ –±–µ—Ä–µ–º —Ç–æ–ø –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ ATR
      candidates.sort(key=lambda x: abs(x['price_change_24h']), reverse=True)
      top_candidates = candidates[:limit * 2]  # –ë–µ—Ä–µ–º —Å –∑–∞–ø–∞—Å–æ–º

      # 4. –ë–∞—Ç—á–µ–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ —Å–≤–µ—á–µ–π –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ ATR
      atr_tasks = []
      for candidate in top_candidates:
        task = self._calculate_atr_for_symbol(candidate['symbol'])
        atr_tasks.append(task)

      atr_results = await asyncio.gather(*atr_tasks, return_exceptions=True)

      # 5. –°–æ–±–∏—Ä–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
      for i, candidate in enumerate(top_candidates):
        atr_percent = atr_results[i] if not isinstance(atr_results[i], Exception) else abs(
          candidate['price_change_24h']) / 10

        volatility_score = abs(candidate['price_change_24h']) * 0.5 + atr_percent * 0.5

        volatility_data.append({
          'symbol': candidate['symbol'],
          'price_change_24h': candidate['price_change_24h'],
          'volume_24h': candidate['volume_24h'],
          'atr_percent': atr_percent,
          'volatility_score': volatility_score
        })

      # 6. –§–∏–Ω–∞–ª—å–Ω–∞—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –ø–æ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
      volatility_data.sort(key=lambda x: x['volatility_score'], reverse=True)

      return volatility_data[:limit]

    except Exception as e:
      logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –±–∞—Ç—á–µ–≤–æ–º –ø–æ–ª—É—á–µ–Ω–∏–∏ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏: {e}")
      return []

  async def _calculate_atr_for_symbol(self, symbol: str) -> float:
    """–í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ ATR"""
    try:
      candles = await self.get_historical_candles(symbol, Timeframe.ONE_HOUR, limit=24)
      if not candles.empty and len(candles) >= 14:
        import pandas_ta as ta
        atr = ta.atr(candles['high'], candles['low'], candles['close'], length=14)
        if atr is not None and not atr.empty:
          current_atr = atr.iloc[-1]
          return (current_atr / candles['close'].iloc[-1]) * 100
      return 0.0
    except Exception:
      return 0.0

  async def _check_symbol_data_availability(self, symbol: str) -> bool:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã—Ö –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–∏–º–≤–æ–ª–∞"""
    try:
      # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –µ—Å–ª–∏ –µ—Å—Ç—å
      cache_key = f"{symbol}_15m_check"
      if cache_key in self.candles_cache and self.candles_cache[cache_key].is_valid():
        return True

      test_data = await self.connector.get_kline(
        symbol, '15', limit=50
      )

      if test_data and len(test_data) >= 50:
        # –ö—ç—à–∏—Ä—É–µ–º —É—Å–ø–µ—à–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É
        self.candles_cache[cache_key] = CachedData(True, 300)  # 5 –º–∏–Ω—É—Ç
        return True

      return False

    except Exception as e:
      logger.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol}: {e}")
      return False

  # –í —Ñ–∞–π–ª–µ: core/data_fetcher.py

  async def get_historical_candles(
      self,
      symbol: str,
      timeframe: Timeframe,
      limit: int = 1000,
      use_cache: bool = True,
      **kwargs  # –î–æ–±–∞–≤–ª—è–µ–º –¥–ª—è –≥–∏–±–∫–æ—Å—Ç–∏
  ) -> pd.DataFrame:
    """
    –ü–æ–ª—É—á–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ —Å–≤–µ—á–∏.
    –ò–°–ü–†–ê–í–õ–ï–ù–û: –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç DatetimeIndex –∏ –ø–µ—Ä–µ–¥–∞–µ—Ç –¥–æ–ø. –∞—Ä–≥—É–º–µ–Ω—Ç—ã.
    """
    self.total_requests += 1

    if kwargs:
      use_cache = False

    cache_key = f"{symbol}_{timeframe.value}_{limit}"

    if use_cache and cache_key in self.candles_cache:
      cached = self.candles_cache[cache_key]
      if cached.is_valid():
        self.cache_hits += 1
        return cached.data

    self.cache_misses += 1

    async with self.fetch_locks[cache_key]:
      if use_cache and cache_key in self.candles_cache and self.candles_cache[cache_key].is_valid():
        return self.candles_cache[cache_key].data

      try:
        interval_map = {
          Timeframe.ONE_MINUTE: '1', Timeframe.FIVE_MINUTES: '5',
          Timeframe.FIFTEEN_MINUTES: '15', Timeframe.THIRTY_MINUTES: '30',
          Timeframe.ONE_HOUR: '60', Timeframe.FOUR_HOURS: '240',
          Timeframe.ONE_DAY: 'D'
        }
        interval = interval_map.get(timeframe)
        if not interval:
          return pd.DataFrame()

        # –ü–µ—Ä–µ–¥–∞–µ–º kwargs –≤ –∫–æ–Ω–Ω–µ–∫—Ç–æ—Ä
        raw_candles = await self.connector.get_kline(symbol, interval, limit=limit, force_fresh=not use_cache, **kwargs)

        if not raw_candles:
          return pd.DataFrame()

        df = pd.DataFrame(raw_candles, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume', 'turnover'])
        df['timestamp'] = pd.to_datetime(df['timestamp'].astype(int), unit='ms', utc=True)

        # --- –ì–õ–ê–í–ù–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï ---
        df.set_index('timestamp', inplace=True)  # –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–ª–∏ —ç—Ç—É —Å—Ç—Ä–æ–∫—É
        # ---------------------------

        for col in ['open', 'high', 'low', 'close', 'volume', 'turnover']:
          df[col] = pd.to_numeric(df[col], errors='coerce')

        df.sort_index(inplace=True)  # –¢–µ–ø–µ—Ä—å —Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞ –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø–æ –≤—Ä–µ–º–µ–Ω–∏

        if use_cache:
          ttl = self.candles_cache_ttl
          if timeframe in [Timeframe.FOUR_HOURS, Timeframe.ONE_DAY]:
            ttl = 300
          self.candles_cache[cache_key] = CachedData(df.copy(), ttl)

        return df

      except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–≤–µ—á–µ–π –¥–ª—è {symbol}: {e}", exc_info=True)
        return pd.DataFrame()

  async def get_absolutely_fresh_candles(self, symbol: str, timeframe: Timeframe, limit: int = 200) -> pd.DataFrame:
    """–ü–æ–ª—É—á–∞–µ—Ç –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ —Å–≤–µ–∂–∏–µ –¥–∞–Ω–Ω—ã–µ, –ø–æ–ª–Ω–æ—Å—Ç—å—é –æ–±—Ö–æ–¥—è –≤—Å–µ –∫—ç—à–∏"""
    try:
      logger.info(f"üîÑ –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–û –ø–æ–ª—É—á–∞–µ–º —Å–≤–µ–∂–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è {symbol}")

      # 1. –û—á–∏—â–∞–µ–º –≤—Å–µ –∫—ç—à–∏
      self.clear_symbol_cache(symbol)
      if hasattr(self.connector, 'clear_symbol_cache'):
        self.connector.clear_symbol_cache(symbol)

      # 2. –î–æ–±–∞–≤–ª—è–µ–º —Å–ª—É—á–∞–π–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä –¥–ª—è –æ–±—Ö–æ–¥–∞ –∫—ç—à–∞
      import random
      random_param = random.randint(1000, 9999)

      # 3. –ü—Ä—è–º–æ–π –∑–∞–ø—Ä–æ—Å –∫ API —Å –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
      interval = timeframe.value
      current_time_ms = int(time.time() * 1000)

      # –ü—Ä—è–º–æ–π –≤—ã–∑–æ–≤ API –±–µ–∑ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è
      raw_candles = await self.connector.get_kline(
        symbol, interval, limit=limit,
        force_fresh=True,
        end=current_time_ms,
        _cache_buster=random_param  # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä –¥–ª—è –æ–±—Ö–æ–¥–∞ –∫—ç—à–∞
      )

      if not raw_candles:
        logger.error(f"‚ùå –ù–µ –ø–æ–ª—É—á–µ–Ω—ã –°–í–ï–ñ–ò–ï –¥–∞–Ω–Ω—ã–µ –¥–ª—è {symbol}")
        return pd.DataFrame()

      # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ DataFrame
      df = pd.DataFrame(raw_candles)
      df.columns = ['timestamp', 'open', 'high', 'low', 'close', 'volume', 'turnover']

      # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
      df['timestamp'] = pd.to_datetime(df['timestamp'].astype(int), unit='ms', utc=True)

      for col in ['open', 'high', 'low', 'close', 'volume', 'turnover']:
        df[col] = pd.to_numeric(df[col], errors='coerce')

      # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –≤—Ä–µ–º–µ–Ω–∏
      df.sort_values('timestamp', inplace=True)

      # –ù–ï –∫—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç!
      logger.info(f"‚úÖ –ü–æ–ª—É—á–µ–Ω—ã –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —Å–≤–µ–∂–∏–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è {symbol}: {len(df)} —Å–≤–µ—á–µ–π")

      # –õ–æ–≥–∏—Ä—É–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω
      if not df.empty:
        first_time = df['timestamp'].iloc[0]
        last_time = df['timestamp'].iloc[-1]
        logger.info(f"üîç –î–∏–∞–ø–∞–∑–æ–Ω –°–í–ï–ñ–ò–• –¥–∞–Ω–Ω—ã—Ö: {first_time} - {last_time}")

      return df

    except Exception as e:
      logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —Å–≤–µ–∂–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol}: {e}")
      return pd.DataFrame()

  async def check_symbol_status(self, symbol: str) -> Dict[str, Any]:
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Å—Ç–∞—Ç—É—Å —Å–∏–º–≤–æ–ª–∞ –Ω–∞ –±–∏—Ä–∂–µ"""
    try:
      # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–∏–∫–µ—Ä–µ
      endpoint = "/v5/market/tickers"
      params = {'category': 'linear', 'symbol': symbol}

      result = await self.connector._make_request('GET', endpoint, params, use_cache=False)

      if result and result.get('list') and len(result['list']) > 0:
        ticker = result['list'][0]

        status_info = {
          'symbol': symbol,
          'exists': True,
          'last_price': float(ticker.get('lastPrice', 0)),
          'volume_24h': float(ticker.get('turnover24h', 0)),
          'price_change_24h': float(ticker.get('price24hPcnt', 0)),
          'status': ticker.get('status', 'unknown')
        }

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∞–∫—Ç–∏–≤–µ–Ω –ª–∏ —Å–∏–º–≤–æ–ª
        if status_info['volume_24h'] < 1000:  # –û—á–µ–Ω—å –Ω–∏–∑–∫–∏–π –æ–±—ä–µ–º
          status_info['warning'] = f"–û—á–µ–Ω—å –Ω–∏–∑–∫–∏–π –æ–±—ä–µ–º: {status_info['volume_24h']}"

        logger.info(f"üìä –°—Ç–∞—Ç—É—Å {symbol}: {status_info}")
        return status_info
      else:
        logger.warning(f"‚ùå –°–∏–º–≤–æ–ª {symbol} –Ω–µ –Ω–∞–π–¥–µ–Ω –∏–ª–∏ –Ω–µ –∞–∫—Ç–∏–≤–µ–Ω")
        return {'symbol': symbol, 'exists': False, 'error': 'not_found'}

    except Exception as e:
      logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å—Ç–∞—Ç—É—Å–∞ {symbol}: {e}")
      return {'symbol': symbol, 'exists': False, 'error': str(e)}

  def clear_symbol_cache(self, symbol: str):
    """–û—á–∏—â–∞–µ—Ç –∫—ç—à –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞"""
    try:
      # –û—á–∏—â–∞–µ–º candles_cache
      keys_to_remove = [key for key in self.candles_cache.keys() if symbol in key]
      for key in keys_to_remove:
        del self.candles_cache[key]

      # –û—á–∏—â–∞–µ–º symbols_cache –µ—Å–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç —ç—Ç–æ—Ç —Å–∏–º–≤–æ–ª
      if self.symbols_cache and self.symbols_cache.data and symbol in self.symbols_cache.data:
        self.symbols_cache = None

      # –û—á–∏—â–∞–µ–º instrument_info_cache
      if symbol in self.instrument_info_cache:
        del self.instrument_info_cache[symbol]

      logger.debug(f"üßπ –û—á–∏—â–µ–Ω DataFetcher –∫—ç—à –¥–ª—è {symbol}: {len(keys_to_remove)} –∑–∞–ø–∏—Å–µ–π")
    except Exception as e:
      logger.error(f"–û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏ DataFetcher –∫—ç—à–∞ –¥–ª—è {symbol}: {e}")

  # –ú–µ—Ç–æ–¥ –¥–ª—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –≤ –∫—ç—à
  async def preload_cache(self, symbols: List[str], timeframes: List[Timeframe]):
    """–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –∑–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ –∫—ç—à –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
    logger.info(f"–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –∫—ç—à–∞ –¥–ª—è {len(symbols)} —Å–∏–º–≤–æ–ª–æ–≤")

    tasks = []
    for symbol in symbols:
      # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞—Ö
      tasks.append(self.get_instrument_info(symbol))

      # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–≤–µ—á–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤
      for timeframe in timeframes:
        tasks.append(self.get_historical_candles(symbol, timeframe))

    # –í—ã–ø–æ–ª–Ω—è–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
    results = await asyncio.gather(*tasks, return_exceptions=True)

    successful = sum(1 for r in results if not isinstance(r, Exception))
    logger.info(f"–ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {successful}/{len(tasks)} —É—Å–ø–µ—à–Ω–æ")

    return successful

  async def get_current_price_safe(self, symbol: str) -> Optional[float]:
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–π —Ü–µ–Ω—ã"""
    try:
      # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –º–µ—Ç–æ–¥ get_candles
      from core.enums import Timeframe
      df = await self.get_historical_candles(
        symbol=symbol,
        timeframe=Timeframe.ONE_MINUTE,
        limit=1
      )

      if not df.empty:
        return float(df['close'].iloc[-1])

      return None

    except Exception as e:
      logger.error(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ü–µ–Ω—ã –¥–ª—è {symbol}: {e}")
      return None

  async def preload_market_data_batch(self, symbols: List[str], timeframe: Timeframe, limit: int = 100):
    """–ü—Ä–µ–¥–∑–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –º–Ω–æ–∂–µ—Å—Ç–≤–∞ —Å–∏–º–≤–æ–ª–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ."""
    try:
      batch_size = 10
      all_data = {}

      for i in range(0, len(symbols), batch_size):
        batch = symbols[i:i + batch_size]

        # –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –∑–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –±–∞—Ç—á–∞
        tasks = []
        for symbol in batch:
          task = self.get_historical_candles(symbol, timeframe, limit)
          tasks.append(task)

        results = await asyncio.gather(*tasks, return_exceptions=True)

        for symbol, result in zip(batch, results):
          if isinstance(result, pd.DataFrame) and not result.empty:
            all_data[symbol] = result
          elif isinstance(result, Exception):
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol}: {result}")

      logger.info(f"‚úÖ –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∂–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –¥–ª—è {len(all_data)} –∏–∑ {len(symbols)} —Å–∏–º–≤–æ–ª–æ–≤")
      return all_data

    except Exception as e:
      logger.error(f"–û—à–∏–±–∫–∞ –±–∞—Ç—á–µ–≤–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
      return {}


