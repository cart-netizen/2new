# rl/train_rl_agent.py

import asyncio
import pandas as pd
import numpy as np
import json
from pathlib import Path
from typing import List, Dict, Optional, Any
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
import seaborn as sns

from config.config_manager import ConfigManager
from core.data_fetcher import DataFetcher
from core.bybit_connector import BybitConnector
from core.enums import Timeframe
from data.database_manager import AdvancedDatabaseManager
from ml.feature_engineering import AdvancedFeatureEngineer
from ml.enhanced_ml_system import EnhancedEnsembleModel
from ml.anomaly_detector import MarketAnomalyDetector
from ml.volatility_system import VolatilityPredictionSystem, ModelType
from core.market_regime_detector import MarketRegimeDetector
from core.risk_manager import AdvancedRiskManager

from rl.environment import BybitTradingEnvironment
from rl.finrl_agent import EnhancedRLAgent
from rl.feature_processor import RLFeatureProcessor
from rl.reward_functions import RiskAdjustedRewardFunction
from rl.data_preprocessor import prepare_data_for_finrl
from stable_baselines3.common.callbacks import BaseCallback
from utils.logging_config import get_logger

logger = get_logger(__name__)


class RLTrainer:
  """–ö–ª–∞—Å—Å –¥–ª—è –æ–±—É—á–µ–Ω–∏—è RL –∞–≥–µ–Ω—Ç–∞ —Å –ø–æ–ª–Ω–æ–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π"""

  def __init__(self, config: Dict[str, Any]):
    self.config_manager = ConfigManager(config_path='../config.json')
    self.config = self.config_manager.load_config()

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    self.connector = None
    self.data_fetcher = None
    self.db_manager = None
    self.feature_engineer = None
    self.ml_model = None
    self.anomaly_detector = None
    self.volatility_predictor = None
    self.market_regime_detector = None
    self.risk_manager = None

    # RL –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
    self.rl_agent = None
    self.feature_processor = None
    self.environment = None

    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è
    self.training_results = {}

  def _load_config(self, config_path: str) -> Dict:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é"""
    try:
      with open(config_path, 'r', encoding='utf-8') as f:
        return json.load(f)
    except Exception as e:
      logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
      return {}

  async def initialize_components(self):
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã"""
    logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è RL...")

    try:
      # –ë–∞–∑–æ–≤—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
      self.connector = BybitConnector()
      self.data_fetcher = DataFetcher(self.connector, self.config)
      self.db_manager = AdvancedDatabaseManager()
      self.feature_processor = RLFeatureProcessor(self.config)

      # ML –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
      self.feature_engineer = AdvancedFeatureEngineer()

      # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º ML –º–æ–¥–µ–ª—å
      self.ml_model = EnhancedEnsembleModel(
        # feature_columns=[],  # –ë—É–¥—É—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏
        # use_market_regime=True,
        # use_correlation_filter=True
      )

      # –î–µ—Ç–µ–∫—Ç–æ—Ä –∞–Ω–æ–º–∞–ª–∏–π
      self.anomaly_detector = MarketAnomalyDetector(
        contamination=0.1,
        # n_estimators=100
        lookback_periods=100
      )

      # –ü—Ä–µ–¥—Å–∫–∞–∑–∞—Ç–µ–ª—å –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
      self.volatility_predictor = VolatilityPredictionSystem(
        model_type=ModelType.LIGHTGBM,
        # prediction_horizon=[1, 3, 5, 10],
        prediction_horizon=5,
        auto_retrain=True
      )

      # –î–µ—Ç–µ–∫—Ç–æ—Ä —Ä–µ–∂–∏–º–æ–≤ —Ä—ã–Ω–∫–∞
      self.market_regime_detector = MarketRegimeDetector(self.data_fetcher)

      # –†–∏—Å–∫-–º–µ–Ω–µ–¥–∂–µ—Ä
      self.risk_manager = AdvancedRiskManager(
        # initial_capital=self.rl_config.get('initial_capital', 10000),
        # db_manager=self.db_manager
        db_manager=self.db_manager,
        settings=self.config,  # self.config —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω —Ä–∞–Ω–µ–µ
        data_fetcher=self.data_fetcher,  # self.data_fetcher —É–∂–µ —Å–æ–∑–¥–∞–Ω
        volatility_predictor=None
      )

      # RL Feature Processor
      self.feature_processor = RLFeatureProcessor(
        feature_engineer=self.feature_engineer,
        config=self.config.get('feature_config', {})
      )

      logger.info("‚úÖ –í—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã")

    except Exception as e:
      logger.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤: {e}", exc_info=True)
      raise

  # async def load_training_data(self) -> Optional[pd.DataFrame]:
  #   """
  #   –ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –ø–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π
  #   –∏ –æ–±–æ–≥–∞—â–µ–Ω–∏–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã —Å–∏–º–≤–æ–ª–æ–≤.
  #   """
  #   logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è...")
  #
  #   # --- –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ "—Å—ã—Ä—ã—Ö" –¥–∞–Ω–Ω—ã—Ö ---
  #   symbols = self.config.get('symbols', ['BTCUSDT', 'ETHUSDT'])
  #   timeframe = Timeframe.ONE_HOUR
  #   limit = self.config.get('training_config', {}).get('history_bars', 2000)
  #
  #   raw_data_dict = {}
  #   for symbol in symbols:
  #     data = await self.data_fetcher.get_historical_candles(
  #       symbol=symbol, timeframe=timeframe, limit=limit
  #     )
  #     if data is not None and not data.empty:
  #       raw_data_dict[symbol] = data
  #
  #   if not raw_data_dict:
  #     raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞")
  #
  #   # --- –®–∞–≥ 2: –í—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏–µ –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –±–∞–∑–æ–≤—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ ---
  #   unaligned_df = prepare_data_for_finrl(raw_data_dict, list(raw_data_dict.keys()))
  #
  #   df_pivot = unaligned_df.pivot(index='date', columns='tic', values='close').dropna()
  #   aligned_df = unaligned_df[unaligned_df.date.isin(df_pivot.index)]
  #
  #   data_with_custom_features = await self._add_technical_indicators(aligned_df)
  #
  #   # --- –®–∞–≥ 3: –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ ML –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã ---
  #   logger.info("–î–æ–±–∞–≤–ª–µ–Ω–∏–µ ML-–ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–π –≥—Ä—É–ø–ø—ã —Å–∏–º–≤–æ–ª–æ–≤...")
  #
  #   tasks = []
  #   # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ 'tic' –∏ –∏—Ç–µ—Ä–∏—Ä—É–µ–º, –ø–æ–ª—É—á–∞—è –∏–º—è –≥—Ä—É–ø–ø—ã (symbol) –∏ —Å–∞–º—É –≥—Ä—É–ø–ø—É (group_df)
  #   for symbol, group_df in data_with_custom_features.groupby('tic'):
  #     tasks.append(self._add_ml_features(group_df, symbol))
  #
  #   # –ó–∞–ø—É—Å–∫–∞–µ–º –∑–∞–¥–∞—á–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
  #   results = await asyncio.gather(*tasks, return_exceptions=True)
  #
  #   # –°–æ–±–∏—Ä–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –≥—Ä—É–ø–ø—ã –æ–±—Ä–∞—Ç–Ω–æ –≤ –æ–¥–∏–Ω DataFrame
  #   processed_groups = [res for res in results if isinstance(res, pd.DataFrame)]
  #   if not processed_groups:
  #     raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –¥–æ–±–∞–≤–∏—Ç—å ML –ø—Ä–∏–∑–Ω–∞–∫–∏ –Ω–∏ –¥–ª—è –æ–¥–Ω–æ–π –≥—Ä—É–ø–ø—ã.")
  #
  #   data_with_ml_features = pd.concat(processed_groups, ignore_index=True)
  #   data_with_ml_features.sort_values(['date', 'tic'], inplace=True)
  #
  #   # --- –®–∞–≥ 4: –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö FinRL –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ ---
  #   finrl_ready_df = self._add_finrl_indicators(data_with_ml_features)
  #
  #   if finrl_ready_df is None or finrl_ready_df.empty:
  #     raise ValueError("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ FinRL")
  #
  #   logger.info(f"üìä –§–∏–Ω–∞–ª—å–Ω–æ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(finrl_ready_df)} –∑–∞–ø–∏—Å–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
  #
  #   return finrl_ready_df

  async def load_training_data(self) -> pd.DataFrame:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∏ –ø–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
    logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è...")

    symbols = self.config.get('symbols', ['BTCUSDT', 'ETHUSDT'])
    timeframe = Timeframe.ONE_HOUR
    limit = self.config.get('training_config', {}).get('history_bars', 2000)

    all_data = {}

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
    for symbol in symbols:
      logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol}...")

      try:
        # –ü–æ–ª—É—á–∞–µ–º –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–µ –¥–∞–Ω–Ω—ã–µ
        data = await self.data_fetcher.get_historical_candles(
          symbol=symbol,
          timeframe=timeframe,
          limit=limit
        )

        if data is not None and not data.empty:
          # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
          data = await self._add_technical_indicators(data)

          # –î–æ–±–∞–≤–ª—è–µ–º ML –ø—Ä–∏–∑–Ω–∞–∫–∏
          data = await self._add_ml_features(data, symbol)

          all_data[symbol] = data
          logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(data)} –±–∞—Ä–æ–≤ –¥–ª—è {symbol}")
        else:
          logger.warning(f"‚ö†Ô∏è –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol}")

      except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol}: {e}")
        continue

    if not all_data:
      raise ValueError("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –Ω–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Å–∏–º–≤–æ–ª–∞")

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç FinRL
    finrl_df = prepare_data_for_finrl(all_data, list(all_data.keys()))

    # –û—Ç–ª–∞–¥–∫–∞
    debug_dataframe_structure(finrl_df, "After prepare_data_for_finrl")

    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ FinRL
    finrl_df = self._add_finrl_indicators(finrl_df)

    # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ç–ª–∞–¥–∫–∞
    debug_dataframe_structure(finrl_df, "Final training data")

    logger.info(f"üìä –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(finrl_df)} –∑–∞–ø–∏—Å–µ–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")

    return finrl_df

  async def _add_technical_indicators(self, data: pd.DataFrame) -> pd.DataFrame:
    """–î–æ–±–∞–≤–ª—è–µ—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã"""
    import pandas_ta as ta

    # RSI
    data['rsi'] = ta.rsi(data['close'], length=14)

    # MACD
    macd = ta.macd(data['close'])
    if macd is not None and not macd.empty:
      data['macd'] = macd.iloc[:, 0]
      data['macd_signal'] = macd.iloc[:, 1]
      data['macd_diff'] = macd.iloc[:, 2]

    # Bollinger Bands
    bb = ta.bbands(data['close'], length=20, std=2)
    if bb is not None and not bb.empty:
      data['bb_lower'] = bb.iloc[:, 0]
      data['bb_middle'] = bb.iloc[:, 1]
      data['bb_upper'] = bb.iloc[:, 2]

    # ATR
    data['atr'] = ta.atr(data['high'], data['low'], data['close'], length=14)

    # ADX
    adx = ta.adx(data['high'], data['low'], data['close'], length=14)
    if adx is not None and not adx.empty:
      data['adx'] = adx.iloc[:, 0]

    # CCI
    data['cci'] = ta.cci(data['high'], data['low'], data['close'], length=20)

    # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏
    data = data.fillna(method='bfill').fillna(0)

    return data

  async def _add_ml_features(self, data: pd.DataFrame, symbol: str) -> pd.DataFrame:
    """–î–æ–±–∞–≤–ª—è–µ—Ç ML –ø—Ä–∏–∑–Ω–∞–∫–∏"""
    try:
      # –î–µ—Ç–µ–∫—Ü–∏—è —Ä–µ–∂–∏–º–∞ —Ä—ã–Ω–∫–∞
      regime = await self.market_regime_detector.detect_regime(symbol, data)

      # –ò–°–ü–†–ê–í–õ–ï–ù–û: RegimeCharacteristics –Ω–µ –∏–º–µ–µ—Ç .value
      if hasattr(regime, 'name'):
        data['market_regime'] = regime.name
      else:
        data['market_regime'] = str(regime) if regime else 'UNKNOWN'

      # –ß–∏—Å–ª–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ä–µ–∂–∏–º–∞
      regime_mapping = {
        'STRONG_TREND_UP': 4,
        'TREND_UP': 3,
        'RANGE_BOUND': 2,
        'TREND_DOWN': 1,
        'STRONG_TREND_DOWN': 0,
        'UNKNOWN': -1
      }
      data['market_regime_numeric'] = regime_mapping.get(data['market_regime'].iloc[-1], -1)

      # –ü—Ä–æ–≥–Ω–æ–∑ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏
      try:
        if hasattr(self.volatility_predictor, 'predict_volatility'):
          vol_pred = self.volatility_predictor.predict_volatility(data)
        elif hasattr(self.volatility_predictor, 'predict_future_volatility'):
          vol_pred = self.volatility_predictor.predict_future_volatility(data)
        else:
          vol_pred = data['close'].pct_change().rolling(20).std().iloc[-1]

        if isinstance(vol_pred, dict):
          data['predicted_volatility'] = vol_pred.get('volatility', 0) or vol_pred.get('predictions', {}).get(1, 0)
        else:
          data['predicted_volatility'] = float(vol_pred) if vol_pred else 0.0
      except Exception as e:
        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–æ–≥–Ω–æ–∑ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏: {e}")
        data['predicted_volatility'] = 0.0

      # –ò–°–ü–†–ê–í–õ–ï–ù–û: —É–±–∏—Ä–∞–µ–º await, —Ç–∞–∫ –∫–∞–∫ detect_anomalies —Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π
      anomaly_reports = self.anomaly_detector.detect_anomalies(data, symbol)
      if anomaly_reports:

        anomaly_score = max(report.severity for report in anomaly_reports)
      else:
        anomaly_score = 0.0
      data['anomaly_score'] = anomaly_score

    except Exception as e:
      logger.error(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è ML –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
      # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
      data['market_regime'] = 'UNKNOWN'
      data['market_regime_numeric'] = -1
      data['predicted_volatility'] = 0.0
      data['anomaly_score'] = 0.0

    return data

  def _add_finrl_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
    """–î–æ–±–∞–≤–ª—è–µ—Ç –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –≤ —Ñ–æ—Ä–º–∞—Ç–µ FinRL –¥–ª—è –≤—Å–µ—Ö —Å–∏–º–≤–æ–ª–æ–≤"""
    if 'tic' not in df.columns:
      raise ValueError("DataFrame –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫—É 'tic'")

    # –°–ø–∏—Å–æ–∫ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –º—ã –±—É–¥–µ–º –¥–æ–±–∞–≤–ª—è—Ç—å
    indicators_config = {
      'rsi': {'default': 50.0, 'required': True},
      'macd': {'default': 0.0, 'required': True},
      'macd_signal': {'default': 0.0, 'required': True},
      'macd_diff': {'default': 0.0, 'required': True},
      'cci': {'default': 0.0, 'required': True},
      'adx': {'default': 25.0, 'required': True},
      'atr': {'default': 0.0, 'required': True}
    }

    result_dfs = []

    for tic in df['tic'].unique():
      tic_df = df[df['tic'] == tic].copy()

      # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ü–µ–Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
      price_cols = ['open', 'high', 'low', 'close', 'volume']
      for col in price_cols:
        if col not in tic_df.columns:
          raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–ª–æ–Ω–∫–∞ {col} –¥–ª—è {tic}")

        # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ —á–∏—Å–ª–æ–≤—ã–µ
        tic_df[col] = pd.to_numeric(tic_df[col], errors='coerce')

      # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
      for indicator, config in indicators_config.items():
        if indicator not in tic_df.columns:
          tic_df[indicator] = config['default']
        else:
          # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ–º —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö
          tic_df[indicator] = pd.to_numeric(tic_df[indicator], errors='coerce').fillna(config['default'])

      # –£–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –Ω–µ—Ç NaN
      tic_df = tic_df.fillna(method='ffill').fillna(method='bfill')

      # –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ –µ—Å—Ç—å NaN, –∑–∞–ø–æ–ª–Ω—è–µ–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
      for col in tic_df.columns:
        if tic_df[col].isna().any():
          if col in indicators_config:
            tic_df[col] = tic_df[col].fillna(indicators_config[col]['default'])
          else:
            tic_df[col] = tic_df[col].fillna(0)

      result_dfs.append(tic_df)

    if not result_dfs:
      raise ValueError("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏")

    # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º
    final_df = pd.concat(result_dfs, ignore_index=True)
    final_df = final_df.sort_values(['date', 'tic']).reset_index(drop=True)

    logger.info(f"–î–æ–±–∞–≤–ª–µ–Ω—ã –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã. –§–∏–Ω–∞–ª—å–Ω–∞—è —Ñ–æ—Ä–º–∞: {final_df.shape}")
    logger.info(f"–ö–æ–ª–æ–Ω–∫–∏: {final_df.columns.tolist()}")

    return final_df

  async def create_environment(self, df: pd.DataFrame) -> BybitTradingEnvironment:
    """–°–æ–∑–¥–∞–µ—Ç —Ç–æ—Ä–≥–æ–≤—É—é —Å—Ä–µ–¥—É"""
    logger.info("–°–æ–∑–¥–∞–Ω–∏–µ —Ç–æ—Ä–≥–æ–≤–æ–π —Å—Ä–µ–¥—ã...")

    # –î–µ—Ç–∞–ª—å–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞
    logger.info(f"–í—Ö–æ–¥–Ω–æ–π DataFrame shape: {df.shape}")
    logger.info(f"Columns: {df.columns.tolist()}")

    if 'tic' in df.columns:
      logger.info(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ tickers: {df['tic'].unique()}")

    if 'date' in df.columns:
      logger.info(f"Date range: {df['date'].min()} to {df['date'].max()}")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
    logger.info(f"DataFrame dtypes:\n{df.dtypes}")
    logger.info(f"–ü–µ—Ä–≤—ã–µ 5 —Å—Ç—Ä–æ–∫:\n{df.head()}")

    # –û—Ç–ª–∞–¥–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö
    debug_dataframe_structure(df, "Before environment creation")

    # –ö–†–ò–¢–ò–ß–ù–û: –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ –¥–ª—è FinRL
    if 'tic' not in df.columns or 'date' not in df.columns:
      raise ValueError("DataFrame –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –∫–æ–ª–æ–Ω–∫–∏ 'tic' –∏ 'date'")

    # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –∏–Ω–¥–µ–∫—Å - —ç—Ç–æ RangeIndex, –∞ –Ω–µ –¥–∞—Ç—ã
    if not isinstance(df.index, pd.RangeIndex):
      df = df.reset_index(drop=True)

    # –ü—Ä–æ–≤–µ—Ä–∏–º –∏ –∏—Å–ø—Ä–∞–≤–∏–º —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
    numeric_columns = ['open', 'high', 'low', 'close', 'volume']
    for col in numeric_columns:
      if col in df.columns:
        df[col] = pd.to_numeric(df[col], errors='coerce')
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ NaN
        if df[col].isna().any():
          logger.warning(f"Found NaN in {col}, filling with forward fill")
          df[col] = df[col].fillna(method='ffill').fillna(method='bfill')

    # –í–ê–ñ–ù–û: FinRL —Ç—Ä–µ–±—É–µ—Ç, —á—Ç–æ–±—ã –¥–∞–Ω–Ω—ã–µ –±—ã–ª–∏ –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω—ã –∏ –≤—ã—Ä–æ–≤–Ω–µ–Ω—ã
    df = df.sort_values(['date', 'tic']).reset_index(drop=True)

    # –°–æ–∑–¥–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è
    reward_function = RiskAdjustedRewardFunction(
      risk_manager=self.risk_manager,
      config=self.config.get('reward_config', {})
    )

    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Å—Ä–µ–¥—ã
    env_config = {
      'hmax': 100,
      'initial_amount': self.config.get('initial_capital', 10000),
      'transaction_cost_pct': 0.001,
      'reward_scaling': 1e-4,
      'buy_cost_pct': 0.001,
      'sell_cost_pct': 0.001
    }

    # –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ç–ª–∞–¥–∫–∞ –ø–µ—Ä–µ–¥ —Å–æ–∑–¥–∞–Ω–∏–µ–º —Å—Ä–µ–¥—ã
    debug_dataframe_structure(df, "Final check before environment")

    try:
      # –°–æ–∑–¥–∞–µ–º —Å—Ä–µ–¥—É
      environment = BybitTradingEnvironment(
        df=df,
        data_fetcher=self.data_fetcher,
        market_regime_detector=self.market_regime_detector,
        risk_manager=self.risk_manager,
        shadow_trading_manager=None,
        feature_engineer=self.feature_engineer,
        initial_balance=env_config['initial_amount'],
        commission_rate=env_config['transaction_cost_pct'],
        leverage=self.config.get('leverage', 10),
        max_positions=self.config.get('portfolio_config', {}).get('max_positions', 10),
        config=env_config
      )

      logger.info("‚úÖ –¢–æ—Ä–≥–æ–≤–∞—è —Å—Ä–µ–¥–∞ —Å–æ–∑–¥–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ")

    except Exception as e:
      logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Å—Ä–µ–¥—ã: {e}")
      logger.error(f"DataFrame info:\n{df.info()}")
      raise

    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è
    environment.reward_function = reward_function

    return environment

  async def train_agent(self, train_df: pd.DataFrame, test_df: pd.DataFrame):
    """–û–±—É—á–∞–µ—Ç RL –∞–≥–µ–Ω—Ç–∞"""
    logger.info("=" * 50)
    logger.info("–ù–ê–ß–ê–õ–û –û–ë–£–ß–ï–ù–ò–Ø RL –ê–ì–ï–ù–¢–ê")
    logger.info("=" * 50)

    # –°–æ–∑–¥–∞–µ–º —Å—Ä–µ–¥—ã –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    train_env = await self.create_environment(train_df)
    test_env = await self.create_environment(test_df)

    # –°–æ–∑–¥–∞–µ–º RL –∞–≥–µ–Ω—Ç–∞
    self.rl_agent = EnhancedRLAgent(
      environment=train_env,
      ml_model=self.ml_model,
      anomaly_detector=self.anomaly_detector,
      volatility_predictor=self.volatility_predictor,
      algorithm=self.config.get('algorithm', 'PPO'),
      config=self.config
    )



    # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è
    training_config = self.config.get('training_config', {})
    total_timesteps = training_config.get('total_timesteps', 100000)
    eval_freq = training_config.get('eval_frequency', 10000)
    save_freq = training_config.get('save_frequency', 20000)



    # –°–æ–∑–¥–∞–µ–º callback –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
    class TrainingCallback(BaseCallback):
      """
      –ö–∞—Å—Ç–æ–º–Ω—ã–π callback –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è
      """

      def __init__(self, trainer, verbose=0):
        super(TrainingCallback, self).__init__(verbose)
        self.trainer = trainer
        self.episode_rewards = []
        self.episode_lengths = []
        self.n_episodes = 0

      def _on_step(self) -> bool:
        """
        –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –Ω–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ —Å—Ä–µ–¥—ã
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —ç–ø–∏–∑–æ–¥–∞
        if self.locals.get('dones', [False])[0]:
          self.n_episodes += 1

          # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–æ—Å–ª–µ–¥–Ω–µ–º —ç–ø–∏–∑–æ–¥–µ
          info = self.locals.get('infos', [{}])[0]
          episode_reward = info.get('episode', {}).get('r', 0)
          episode_length = info.get('episode', {}).get('l', 0)

          self.episode_rewards.append(episode_reward)
          self.episode_lengths.append(episode_length)

          # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫–∞–∂–¥—ã–µ 10 —ç–ø–∏–∑–æ–¥–æ–≤
          if self.n_episodes % 10 == 0:
            avg_reward = np.mean(self.episode_rewards[-10:]) if self.episode_rewards else 0
            avg_length = np.mean(self.episode_lengths[-10:]) if self.episode_lengths else 0

            logger.info(f"\n{'=' * 50}")
            logger.info(f"–≠–ø–∏–∑–æ–¥: {self.n_episodes}")
            logger.info(f"–°—Ä–µ–¥–Ω—è—è –Ω–∞–≥—Ä–∞–¥–∞ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 10): {avg_reward:.2f}")
            logger.info(f"–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —ç–ø–∏–∑–æ–¥–∞: {avg_length:.0f}")
            logger.info(f"–í—Å–µ–≥–æ —à–∞–≥–æ–≤: {self.num_timesteps}")
            logger.info(f"{'=' * 50}\n")

        # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 5000 —à–∞–≥–æ–≤
        if self.num_timesteps % 5000 == 0 and self.num_timesteps > 0:
          logger.info(f"–ü—Ä–æ–≥—Ä–µ—Å—Å: {self.num_timesteps} —à–∞–≥–æ–≤ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ")

        return True  # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ

      def _on_rollout_end(self) -> None:
        """
        –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –≤ –∫–æ–Ω—Ü–µ rollout
        """
        pass

      def _on_training_end(self) -> None:
        """
        –í—ã–∑—ã–≤–∞–µ—Ç—Å—è –≤ –∫–æ–Ω—Ü–µ –æ–±—É—á–µ–Ω–∏—è
        """
        logger.info("–û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")

      def __call__(self, locals_dict, globals_dict):
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        if 'episode_rewards' in locals_dict:
          self.episode_rewards.extend(locals_dict['episode_rewards'])
        if 'episode_lengths' in locals_dict:
          self.episode_lengths.extend(locals_dict['episode_lengths'])

        # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 1000 —à–∞–≥–æ–≤
        if locals_dict['self'].num_timesteps % 1000 == 0:
          logger.info(f"–®–∞–≥ {locals_dict['self'].num_timesteps}/{total_timesteps}")
          if self.episode_rewards:
            avg_reward = np.mean(self.episode_rewards[-10:])
            logger.info(f"–°—Ä–µ–¥–Ω—è—è –Ω–∞–≥—Ä–∞–¥–∞ (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 10 —ç–ø–∏–∑–æ–¥–æ–≤): {avg_reward:.2f}")

        return True

    callback = TrainingCallback(self, verbose=1)

    # –û–±—É—á–∞–µ–º –∞–≥–µ–Ω—Ç–∞
    logger.info(f"–û–±—É—á–µ–Ω–∏–µ {self.config.get('algorithm', 'PPO')} –Ω–∞ {total_timesteps} —à–∞–≥–æ–≤...")

    self.rl_agent.train(
      total_timesteps=total_timesteps,
      callback=callback,
      log_interval=100,
      eval_env=test_env,
      eval_freq=eval_freq,
      n_eval_episodes=5,
      save_freq=save_freq
    )

    # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –æ–±—É—á–µ–Ω–∏—è
    logger.info("\n" + "=" * 60)
    logger.info("–ê–ù–ê–õ–ò–ó –†–ï–ó–£–õ–¨–¢–ê–¢–û–í –û–ë–£–ß–ï–ù–ò–Ø")
    logger.info("=" * 60)

    if hasattr(callback, 'episode_rewards') and callback.episode_rewards:
      total_episodes = len(callback.episode_rewards)
      avg_reward = np.mean(callback.episode_rewards)
      std_reward = np.std(callback.episode_rewards)
      max_reward = np.max(callback.episode_rewards)
      min_reward = np.min(callback.episode_rewards)

      logger.info(f"–í—Å–µ–≥–æ —ç–ø–∏–∑–æ–¥–æ–≤: {total_episodes}")
      logger.info(f"–°—Ä–µ–¥–Ω—è—è –Ω–∞–≥—Ä–∞–¥–∞: {avg_reward:.2f} ¬± {std_reward:.2f}")
      logger.info(f"–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –Ω–∞–≥—Ä–∞–¥–∞: {max_reward:.2f}")
      logger.info(f"–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –Ω–∞–≥—Ä–∞–¥–∞: {min_reward:.2f}")

      # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç—Ä–µ–Ω–¥
      if total_episodes > 20:
        early_avg = np.mean(callback.episode_rewards[:10])
        late_avg = np.mean(callback.episode_rewards[-10:])
        improvement = ((late_avg - early_avg) / abs(early_avg)) * 100 if early_avg != 0 else 0

        logger.info(f"\n–£–ª—É—á—à–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏:")
        logger.info(f"–ü–µ—Ä–≤—ã–µ 10 —ç–ø–∏–∑–æ–¥–æ–≤: {early_avg:.2f}")
        logger.info(f"–ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 —ç–ø–∏–∑–æ–¥–æ–≤: {late_avg:.2f}")
        logger.info(f"–ò–∑–º–µ–Ω–µ–Ω–∏–µ: {improvement:+.1f}%")

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è
    self.training_results = {
      'algorithm': self.config.get('algorithm', 'PPO'),
      'total_timesteps': total_timesteps,
      'episode_rewards': callback.episode_rewards,
      'episode_lengths': callback.episode_lengths,
      'training_time': datetime.now().isoformat(),
      'symbols': self.config.get('symbols', []),
      'final_stats': self.rl_agent.get_training_stats()
    }

    logger.info("=" * 50)
    logger.info("–û–ë–£–ß–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û")
    logger.info(f"–§–∏–Ω–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {self.training_results['final_stats']}")
    logger.info("=" * 50)

  async def evaluate_agent(self, test_df: pd.DataFrame):
    """–û—Ü–µ–Ω–∏–≤–∞–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞–≥–µ–Ω—Ç–∞"""
    logger.info("–û—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∞–≥–µ–Ω—Ç–∞...")

    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—É—é —Å—Ä–µ–¥—É
    test_env = await self.create_environment(test_df)

    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    # –ò–°–ü–†–ê–í–õ–ï–ù–û: –ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤–æ–∑–≤—Ä–∞—Ç reset()
    obs, info = test_env.reset()  # reset –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ—Ä—Ç–µ–∂
    done = False
    truncated = False

    rewards = []
    actions = []
    portfolio_values = []

    # –ò–°–ü–†–ê–í–õ–ï–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç–µ–∫—É—â–µ–≥–æ –±–∞–ª–∞–Ω—Å–∞
    initial_balance = test_env.initial_amount if hasattr(test_env, 'initial_amount') else 10000
    portfolio_values.append(initial_balance)

    while not done and not truncated:
      # –ü–æ–ª—É—á–∞–µ–º –¥–µ–π—Å—Ç–≤–∏–µ –æ—Ç –∞–≥–µ–Ω—Ç–∞
      action, _ = self.rl_agent.predict(obs, deterministic=True)  # obs —É–∂–µ numpy array

      # –í—ã–ø–æ–ª–Ω—è–µ–º –¥–µ–π—Å—Ç–≤–∏–µ
      obs, reward, done, truncated, info = test_env.step(action)  # 5 –≤–æ–∑–≤—Ä–∞—â–∞–µ–º—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π

      # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
      rewards.append(reward)
      actions.append(action)

      # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–∏–π –±–∞–ª–∞–Ω—Å –∏–∑ —Å–æ—Å—Ç–æ—è–Ω–∏—è
      if isinstance(obs, np.ndarray) and len(obs) > 0:
        current_balance = obs[0]  # –ü–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç —Å–æ—Å—Ç–æ—è–Ω–∏—è - —ç—Ç–æ –±–∞–ª–∞–Ω—Å
        portfolio_values.append(current_balance)

    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    if len(portfolio_values) > 1:
      total_return = (portfolio_values[-1] - portfolio_values[0]) / portfolio_values[0]
    else:
      total_return = 0

    sharpe_ratio = self._calculate_sharpe_ratio(rewards)
    max_drawdown = self._calculate_max_drawdown(portfolio_values)
    win_rate = sum(1 for r in rewards if r > 0) / len(rewards) if rewards else 0

    evaluation_results = {
      'total_return': total_return,
      'total_return_pct': total_return * 100,
      'sharpe_ratio': sharpe_ratio,
      'max_drawdown': max_drawdown,
      'win_rate': win_rate,
      'total_trades': len([a for a in actions if np.any(a != 0)]),  # –ù–µ —Å—á–∏—Ç–∞–µ–º –Ω—É–ª–µ–≤—ã–µ –¥–µ–π—Å—Ç–≤–∏—è
      'final_portfolio_value': portfolio_values[-1] if portfolio_values else initial_balance,
      'total_rewards': sum(rewards)
    }

    self.training_results['evaluation'] = evaluation_results

    logger.info("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ—Ü–µ–Ω–∫–∏:")
    logger.info(f"  –û–±—â–∞—è –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç—å: {total_return * 100:.2f}%")
    logger.info(f"  Sharpe Ratio: {sharpe_ratio:.2f}")
    logger.info(f"  –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –ø—Ä–æ—Å–∞–¥–∫–∞: {max_drawdown * 100:.2f}%")
    logger.info(f"  Win Rate: {win_rate * 100:.2f}%")
    logger.info(f"  –í—Å–µ–≥–æ —Å–¥–µ–ª–æ–∫: {evaluation_results['total_trades']}")

    return evaluation_results

  def _calculate_sharpe_ratio(self, returns: List[float]) -> float:
    """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç Sharpe Ratio"""
    if not returns or len(returns) < 2:
      return 0

    returns_array = np.array(returns)
    if np.std(returns_array) == 0:
      return 0

    # Annualized Sharpe
    sharpe = np.mean(returns_array) / np.std(returns_array) * np.sqrt(252)
    return sharpe

  def _calculate_max_drawdown(self, values: List[float]) -> float:
    """–†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç –º–∞–∫—Å–∏–º–∞–ª—å–Ω—É—é –ø—Ä–æ—Å–∞–¥–∫—É"""
    if not values:
      return 0

    peak = values[0]
    max_dd = 0

    for value in values:
      if value > peak:
        peak = value
      drawdown = (peak - value) / peak
      max_dd = max(max_dd, drawdown)

    return max_dd

  def save_results(self):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è"""
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    results_dir = Path("rl/training_results")
    results_dir.mkdir(parents=True, exist_ok=True)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    model_name = f"{self.config.get('algorithm', 'PPO')}_{timestamp}"
    self.rl_agent.save_model(model_name)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    results_file = results_dir / f"training_results_{timestamp}.json"
    with open(results_file, 'w') as f:
      json.dump(self.training_results, f, indent=2, default=str)

    # –°–æ–∑–¥–∞–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
    self._create_visualizations(results_dir, timestamp)

    logger.info(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {results_dir}")
    logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –∫–∞–∫ {model_name}")

  def _create_visualizations(self, results_dir: Path, timestamp: str):
    """–°–æ–∑–¥–∞–µ—Ç –≥—Ä–∞—Ñ–∏–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
    try:
      plt.style.use('seaborn-v0_8-darkgrid')
      fig, axes = plt.subplots(2, 2, figsize=(15, 10))

      # –ì—Ä–∞—Ñ–∏–∫ –Ω–∞–≥—Ä–∞–¥ –ø–æ —ç–ø–∏–∑–æ–¥–∞–º
      if self.training_results.get('episode_rewards'):
        ax = axes[0, 0]
        rewards = self.training_results['episode_rewards']
        ax.plot(rewards, alpha=0.3, label='Episode Rewards')

        # –°–∫–æ–ª—å–∑—è—â–µ–µ —Å—Ä–µ–¥–Ω–µ–µ
        if len(rewards) > 10:
          ma = pd.Series(rewards).rolling(10).mean()
          ax.plot(ma, label='MA(10)', linewidth=2)

        ax.set_title('Episode Rewards During Training')
        ax.set_xlabel('Episode')
        ax.set_ylabel('Reward')
        ax.legend()

      # –ì—Ä–∞—Ñ–∏–∫ –¥–ª–∏–Ω—ã —ç–ø–∏–∑–æ–¥–æ–≤
      if self.training_results.get('episode_lengths'):
        ax = axes[0, 1]
        lengths = self.training_results['episode_lengths']
        ax.plot(lengths, alpha=0.5)
        ax.set_title('Episode Lengths')
        ax.set_xlabel('Episode')
        ax.set_ylabel('Length')

      # –ì—Ä–∞—Ñ–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
      if 'evaluation' in self.training_results:
        ax = axes[1, 0]
        eval_data = self.training_results['evaluation']

        metrics = ['total_return_pct', 'sharpe_ratio', 'win_rate']
        values = [
          eval_data.get('total_return_pct', 0),
          eval_data.get('sharpe_ratio', 0) * 10,  # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
          eval_data.get('win_rate', 0) * 100
        ]
        labels = ['Return %', 'Sharpe x10', 'Win Rate %']

        bars = ax.bar(labels, values)
        ax.set_title('Performance Metrics')
        ax.set_ylabel('Value')

        # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
        for bar, value in zip(bars, values):
          height = bar.get_height()
          ax.text(bar.get_x() + bar.get_width() / 2., height,
                  f'{value:.1f}',
                  ha='center', va='bottom')

      # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
      ax = axes[1, 1]
      ax.axis('off')

      info_text = f"""
            Model Information:

            Algorithm: {self.config.get('algorithm', 'PPO')}
            Total Timesteps: {self.training_results.get('total_timesteps', 0):,}
            Training Time: {timestamp}

            Symbols: {', '.join(self.config.get('symbols', []))}

            Final Stats:
            {json.dumps(self.training_results.get('final_stats', {}), indent=2)}
            """

      ax.text(0.1, 0.9, info_text, transform=ax.transAxes,
              fontsize=10, verticalalignment='top', fontfamily='monospace')

      plt.tight_layout()
      plt.savefig(results_dir / f"training_results_{timestamp}.png", dpi=300, bbox_inches='tight')
      plt.close()

      logger.info("üìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ–∑–¥–∞–Ω–∞")

    except Exception as e:
      logger.error(f"–û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏: {e}")


async def main_training():
  """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –æ–±—É—á–µ–Ω–∏—è"""
  logger.info("=" * 80)
  logger.info("–ó–ê–ü–£–°–ö –û–ë–£–ß–ï–ù–ò–Ø RL –ê–ì–ï–ù–¢–ê")
  logger.info("=" * 80)

  # –°–æ–∑–¥–∞–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
  import os
  os.makedirs('results', exist_ok=True)
  os.makedirs('rl/models', exist_ok=True)
  os.makedirs('rl/models/logs', exist_ok=True)
  os.makedirs('rl/models/best_model', exist_ok=True)
  os.makedirs('rl/models/eval_logs', exist_ok=True)
  logger.info("üöÄ –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è RL –∞–≥–µ–Ω—Ç–∞")
  trainer = None
  # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –ü–ï–†–ï–î —Å–æ–∑–¥–∞–Ω–∏–µ–º —Ç—Ä–µ–π–Ω–µ—Ä–∞.
  # –ü—É—Ç—å '../config.json' —É–∫–∞–∑—ã–≤–∞–µ—Ç, —á—Ç–æ —Ñ–∞–π–ª –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –ø–∞–ø–∫–µ config
  # –Ω–∞ –æ–¥–∏–Ω —É—Ä–æ–≤–µ–Ω—å –≤—ã—à–µ, —á–µ–º –ø–∞–ø–∫–∞ rl.
  # –ï—Å–ª–∏ config.json –≤ –∫–æ—Ä–Ω–µ, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ path='../config.json'
  try:
    # –ö–æ—Ä—Ä–µ–∫—Ç–∏—Ä—É–µ–º –ø—É—Ç—å: ../ –æ–∑–Ω–∞—á–∞–µ—Ç "–Ω–∞ –æ–¥–∏–Ω —É—Ä–æ–≤–µ–Ω—å –≤–≤–µ—Ä—Ö" –æ—Ç –ø–∞–ø–∫–∏ rl
    config_manager = ConfigManager(config_path='../config.json')
    config = config_manager.load_config()
    logger.info("‚úÖ –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞.")
  except Exception as e:
    logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏: {e}")
    return

  # 2. –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä RLTrainer, –ü–ï–†–ï–î–ê–í–ê–Ø –µ–º—É –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π –∫–æ–Ω—Ñ–∏–≥.
  trainer = RLTrainer(config)

  # 3. –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é –ª–æ–≥–∏–∫—É —Ä–∞–±–æ—Ç—ã
  try:
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    await trainer.initialize_components()

    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    df = await trainer.load_training_data()

    # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∑–∏–ª–∏—Å—å, –ø—Ä–µ–∫—Ä–∞—â–∞–µ–º —Ä–∞–±–æ—Ç—É
    if df is None or df.empty:
      logger.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è. –ü—Ä–æ—Ü–µ—Å—Å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.")
      return

    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test
    train_size = int(len(df) * 0.8)
    train_df = df[:train_size]
    test_df = df[train_size:]

    logger.info(f"üìä –î–∞–Ω–Ω—ã–µ —Ä–∞–∑–¥–µ–ª–µ–Ω—ã: train={len(train_df)}, test={len(test_df)}")

    # –û–±—É—á–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–∞
    await trainer.train_agent(train_df, test_df)

    # –û—Ü–µ–Ω–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    await trainer.evaluate_agent(test_df)

    # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    trainer.save_results()

    logger.info("‚úÖ –û–±—É—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")

  except Exception as e:
    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞ –æ–±—É—á–µ–Ω–∏—è: {e}", exc_info=True)
    raise  # –ü–æ–≤—Ç–æ—Ä–Ω–æ –≤—ã–∑—ã–≤–∞–µ–º –æ—à–∏–±–∫—É –¥–ª—è –ø–æ–ª–Ω–æ–π –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏
  finally:
    # –ó–∞–∫—Ä—ã–≤–∞–µ–º –≤—Å–µ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è
    if trainer and hasattr(trainer, 'connector') and trainer.connector:
      await trainer.connector.close()
    if trainer and hasattr(trainer, 'data_fetcher') and hasattr(trainer.data_fetcher, 'connector'):
      await trainer.data_fetcher.connector.close()

def validate_finrl_dataframe(df: pd.DataFrame) -> pd.DataFrame:
    """
    –í–∞–ª–∏–¥–∏—Ä—É–µ—Ç –∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç DataFrame –¥–ª—è FinRL
    """
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–ª–æ–Ω–∫–∏
    required_columns = ['date', 'tic', 'open', 'high', 'low', 'close', 'volume']

    for col in required_columns:
      if col not in df.columns:
        raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–∞—è –∫–æ–ª–æ–Ω–∫–∞: {col}")

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —É –Ω–∞—Å –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Å–µ—Ö —Å–∏–º–≤–æ–ª–æ–≤ –Ω–∞ –∫–∞–∂–¥—É—é –¥–∞—Ç—É
    # –≠—Ç–æ –∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è FinRL!
    date_tic_combinations = df.groupby(['date', 'tic']).size()
    dates = df['date'].unique()
    tics = df['tic'].unique()

    # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π –Ω–∞–±–æ—Ä –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –¥–∞—Ç–∞-—Å–∏–º–≤–æ–ª
    full_index = pd.MultiIndex.from_product([dates, tics], names=['date', 'tic'])

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏
    missing_combinations = set(full_index) - set(date_tic_combinations.index)

    if missing_combinations:
      logger.warning(f"–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {len(missing_combinations)} –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∫–æ–º–±–∏–Ω–∞—Ü–∏–π –¥–∞—Ç–∞-—Å–∏–º–≤–æ–ª")

      # –ó–∞–ø–æ–ª–Ω—è–µ–º –ø—Ä–æ–ø—É—Å–∫–∏
      for date, tic in missing_combinations:
        # –ù–∞—Ö–æ–¥–∏–º –±–ª–∏–∂–∞–π—à—É—é –¥–æ—Å—Ç—É–ø–Ω—É—é –∑–∞–ø–∏—Å—å –¥–ª—è —ç—Ç–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
        tic_data = df[df['tic'] == tic]
        if len(tic_data) > 0:
          # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –∏–∑–≤–µ—Å—Ç–Ω—É—é —Ü–µ–Ω—É
          last_known = tic_data[tic_data['date'] < date].iloc[-1] if len(tic_data[tic_data['date'] < date]) > 0 else \
          tic_data.iloc[0]

          new_row = last_known.copy()
          new_row['date'] = date
          new_row['volume'] = 0  # –ù—É–ª–µ–≤–æ–π –æ–±—ä–µ–º –¥–ª—è –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –¥–Ω–µ–π

          df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ –∏ —Å–∏–º–≤–æ–ª—É
    df = df.sort_values(['date', 'tic']).reset_index(drop=True)

    # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ - —É–±–µ–∂–¥–∞–µ–º—Å—è, —á—Ç–æ –≤—Å–µ —á–∏—Å–ª–æ–≤—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —á–∏—Å–ª–æ–≤—ã–µ
    numeric_cols = ['open', 'high', 'low', 'close', 'volume']
    for col in numeric_cols:
      df[col] = pd.to_numeric(df[col], errors='coerce').fillna(method='ffill').fillna(0)

    return df


def debug_dataframe_structure(df: pd.DataFrame, stage: str = ""):
  """–û—Ç–ª–∞–¥–∫–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã DataFrame –¥–ª—è FinRL"""
  logger.info(f"\n{'=' * 50}")
  logger.info(f"DEBUG DataFrame Structure - {stage}")
  logger.info(f"{'=' * 50}")
  logger.info(f"Shape: {df.shape}")
  logger.info(f"Columns: {df.columns.tolist()}")
  logger.info(f"Index: {df.index.name} - {type(df.index)}")
  logger.info(f"Dtypes:\n{df.dtypes}")

  if 'tic' in df.columns:
    logger.info(f"Unique tickers: {df['tic'].unique()}")
    logger.info(f"Ticker counts:\n{df['tic'].value_counts()}")

  if 'date' in df.columns:
    logger.info(f"Date range: {df['date'].min()} to {df['date'].max()}")
    logger.info(f"Unique dates: {df['date'].nunique()}")

  # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –¥—É–±–ª–∏–∫–∞—Ç—ã
  if 'date' in df.columns and 'tic' in df.columns:
    duplicates = df.duplicated(subset=['date', 'tic'])
    if duplicates.any():
      logger.warning(f"Found {duplicates.sum()} duplicate date-tic combinations!")

  # –ü—Ä–∏–º–µ—Ä –ø–µ—Ä–≤—ã—Ö —Å—Ç—Ä–æ–∫
  logger.info(f"First 5 rows:\n{df.head()}")
  logger.info(f"{'=' * 50}\n")


if __name__ == "__main__":
  asyncio.run(main_training())